{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de10f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from kneed import KneeLocator\n",
    "from sklearn.decomposition import PCA\n",
    "from Style import Configure as Conf\n",
    "import Measurements as M\n",
    "from operator import itemgetter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76527ba2",
   "metadata": {},
   "source": [
    "Dataset is a class created for orgenaize the data and the results.\n",
    "The variables in the class are 3 tuple contains three list:\n",
    "1. dataset paths.\n",
    "2. the data frames.\n",
    "3. the prediction.\n",
    "one tuple for training datasets.\n",
    "one for positive test set (contains normal datasets).\n",
    "and one for negative test set ( contains abnormal datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2aec735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Dataset as DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06ac850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mic_topics(exp):\n",
    "    if \"panda\" in exp:\n",
    "        topics = []\n",
    "        for epv in ['effort', 'position', 'velocity']:\n",
    "            for i in range(1, 8):\n",
    "                topics.append('panda_joint' + str(i) + ' ' + epv)\n",
    "            for i in range(1, 3):\n",
    "                topics.append('panda_finger_joint' + str(i) + ' ' + epv)\n",
    "    else:\n",
    "        topics = ['linear velocity x', 'linear velocity y', 'angular velocity z']\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673fd26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_influence_feature_by_pca(datasets, n=25):\n",
    "    trainings, positives, negatives = datasets\n",
    "    # t_df = pd.concat(trainings, ignore_index=True)\n",
    "    initial_feature_names = trainings[0].columns\n",
    "    dic = dict.fromkeys(range(0, trainings[0].shape[1]), 0)\n",
    "    for training in trainings:\n",
    "        pca = PCA(n_components=n)\n",
    "        pca = pca.fit(training)\n",
    "        for arr in pca.components_:\n",
    "            abs_arr = np.abs(arr)\n",
    "            for i in range(len(abs_arr)):\n",
    "                dic[i] += abs_arr[i]\n",
    "    dic_most_important_feature = dict(sorted(dic.items(), key=itemgetter(1), reverse=True)[:n])\n",
    "    most_important_index = list(dic_most_important_feature.keys())\n",
    "    # get the names\n",
    "    most_important_names = [initial_feature_names[most_important_index[i]] for i in range(n)]\n",
    "    return most_important_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132bee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_topics(datasets, topics=None):\n",
    "    if topics is None:\n",
    "        topics = []\n",
    "    trainings, positives, negatives = datasets\n",
    "    flt_training = list(map(lambda df: df[topics], trainings))\n",
    "    flt_positive = list(map(lambda df: df[topics], positives))\n",
    "    flt_negative = list(map(lambda df: df[topics], negatives))\n",
    "    return flt_training, flt_positive, flt_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de366ce2",
   "metadata": {},
   "source": [
    "# DBSCAN - Density-Based Spatial Clustering of Applications with Noise\n",
    "DBSCAN algorithm need two parameter:\n",
    "\n",
    "*EPS* - The maximum distance between two points for them to be considered neighbors. Points that are within eps distance of each other are considered part of the same cluster.\n",
    "\n",
    "*min_group* - The minimum number of points required for a point to be considered a core point. Points that have fewer than min_samples neighbors are labeled as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b597fa",
   "metadata": {},
   "source": [
    "Calculate EPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfca293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eps(x_train, min_group):\n",
    "    nbrs = NearestNeighbors(n_neighbors=min_group - 1).fit(x_train)\n",
    "    distances, indices = nbrs.kneighbors(x_train)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:, 1]\n",
    "    # plt.plot(distances)\n",
    "    # plt.show()\n",
    "    from scipy.signal import savgol_filter\n",
    "    sg_distances = savgol_filter(distances, 51, 2)\n",
    "    # plt.plot(range(1, len(sg_distances) + 1), sg_distances, range(1, len(sg_distances) + 1), distances)\n",
    "    # plt.show()\n",
    "    kneedle = KneeLocator(range(1, len(sg_distances) + 1),  # x values\n",
    "                          sg_distances,  # y values\n",
    "                          S=0,  # measure of how many “flat” points we expect to see in the unmodified data curve\n",
    "                          curve=\"convex\",  # parameter from figure concave/convex\n",
    "                          online=True,\n",
    "                          direction=\"increasing\")  # parameter from figure\n",
    "    eps = kneedle.knee_y\n",
    "    Xtrain = x_train.to_numpy()\n",
    "    eps_calibration = True\n",
    "    predictions = []\n",
    "    i_pred = []\n",
    "    predicts = []\n",
    "    while(eps_calibration):\n",
    "        labels_ = DBSCAN(eps=eps, min_samples=min_group).fit_predict(Xtrain)\n",
    "        predicts = labels_\n",
    "        fp_labels = [i for i in labels_ if i < 0]\n",
    "        if len(fp_labels)/len(labels_) > 0.1:\n",
    "            eps += 0.04\n",
    "        else:\n",
    "            eps_calibration = False\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f829a3",
   "metadata": {},
   "source": [
    "Input: data-sets\n",
    "output: all training-sets in one dataframe, and all test-sets (positive and negative) in one dataframe, and all data-sets (training and test) in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7907a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_datasets(datasets):\n",
    "    trainings, positives, negatives = datasets\n",
    "    training = pd.concat(trainings, ignore_index=True)\n",
    "    positive = pd.concat(positives, ignore_index=True)\n",
    "    negative = pd.concat(negatives, ignore_index=True)\n",
    "    x_train = training\n",
    "    x_test = pd.concat([positive, negative], ignore_index=True)\n",
    "    x_dfs = pd.concat([training, positive, negative], ignore_index=True)\n",
    "    return x_train, x_test, x_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf59803",
   "metadata": {},
   "source": [
    "input: get concate dataframe and concate predication, and the data-sets at the begining\n",
    "output: datasets and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9423fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_concat_to_datasets_n_prediction(Xdf, Ydf, datasets):\n",
    "    count = 0\n",
    "    trainings, positives, negatives = datasets\n",
    "    new_trainings_dataset = []\n",
    "    new_trainings_predicts = []\n",
    "    for train in trainings:\n",
    "        dataset = Xdf.iloc[count:train.shape[0]+count, :]\n",
    "        predicts = Ydf[count:train.shape[0]+count]\n",
    "        new_trainings_dataset.append(dataset)\n",
    "        new_trainings_predicts.append(predicts)\n",
    "        count += train.shape[0]\n",
    "    new_positives_dataset = []\n",
    "    new_positives_predicts =[]\n",
    "    for pos in positives:\n",
    "        dataset = Xdf.iloc[count:pos.shape[0]+count, :]\n",
    "        predicts = Ydf[count:pos.shape[0]+count]\n",
    "        new_positives_dataset.append(dataset)\n",
    "        new_positives_predicts.append(predicts)\n",
    "        count += pos.shape[0]\n",
    "    new_negatives_dataset = []\n",
    "    new_negatives_predicts = []\n",
    "    for neg in negatives:\n",
    "        dataset = Xdf.iloc[count:neg.shape[0]+count, :]\n",
    "        predicts = Ydf[count:neg.shape[0]+count]\n",
    "        new_negatives_dataset.append(dataset)\n",
    "        new_negatives_predicts.append(predicts)\n",
    "        count += neg.shape[0]\n",
    "    p_datasets = new_trainings_predicts, new_positives_predicts, new_negatives_predicts\n",
    "    n_datasets = new_trainings_dataset, new_positives_dataset, new_negatives_dataset\n",
    "    return n_datasets, p_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274af2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(class_trains, sample, max_dist):\n",
    "    min_dist = np.min(cdist(class_trains, [sample]))\n",
    "    if max_dist >= min_dist:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b8cbb",
   "metadata": {},
   "source": [
    "run DBSCAN only on the training set will the test set examinee \"online\" based on the trainig set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c85a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dbscan(datasets, my_eps=0, min_group=0):\n",
    "    Xtrain, Xtest, Xdfs = concat_datasets(datasets)\n",
    "    if min_group == 0:\n",
    "        min_group = Xdfs.shape[1] + 1 #based on יeuristic\n",
    "    if my_eps == 0:\n",
    "        my_eps = find_eps(x_train=Xtrain, min_group=min_group) \n",
    "    Xtrain = Xtrain.to_numpy()\n",
    "    Xtest = Xtest.to_numpy()\n",
    "    predicts = DBSCAN(eps=my_eps, min_samples=min_group).fit_predict(Xtrain)\n",
    "    predictions = []\n",
    "    i_pred = []\n",
    "    for i in range(0, len(predicts), 1):\n",
    "        if predicts[i] >= 0:\n",
    "            predictions.append(1)\n",
    "            i_pred.append(i)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    print(\"----------------------- EPS =     \" + str(my_eps) + \"    min group =    \" + str(min_group) +\n",
    "          \"  -----------------------\")\n",
    "    # update the datasets_preds\n",
    "    pos_train = [Xtrain[i] for i in i_pred]\n",
    "    if len(i_pred) < 1:\n",
    "        print(\"Error\")\n",
    "    \n",
    "    #check for each sample in test-set if it anomaly or normal\n",
    "    for sample in Xtest:\n",
    "        predictions.append(predict_sample(pos_train, sample, my_eps))\n",
    "\n",
    "    dfs, n_dfs = convert_concat_to_datasets_n_prediction(Xdfs, predictions, datasets)\n",
    "    return dfs, n_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9043a12",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23cff504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_longest_sequence(trainings_names, trainings_preds, alpha=0.95):\n",
    "    longests = []\n",
    "    for f, y_pred in zip(trainings_names, trainings_preds):\n",
    "        longest = M.Measurements.longest_sequence(y_pred, Conf.NEGATIVE_LABEL)\n",
    "        longests.append(longest)\n",
    "    longests.sort()\n",
    "    max_longest = longests[int(round(len(longests) * alpha)) - 1]\n",
    "    # print(longests)\n",
    "    # print(\"max:    \" + str(max_longest))\n",
    "    return max_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67f42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_sum_preds(multi_paths_preds, max_longest, dict_preds={}):\n",
    "    for paths_preds in multi_paths_preds:\n",
    "        for f, y_pred in paths_preds:\n",
    "            if f not in dict_preds:\n",
    "                dict_preds[f] = 0\n",
    "            warning = M.Measurements.count_warnings(y_pred, Conf.NEGATIVE_LABEL, max_longest + 1)\n",
    "            if warning > 0:\n",
    "                dict_preds[f] += 1\n",
    "    return dict_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ad844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_result(dict_results):\n",
    "    tmp = \"not exist file\"\n",
    "    count = 0\n",
    "    anomaly_count = 0\n",
    "    lst = []\n",
    "    for key in dict_results.keys():\n",
    "        if tmp not in key:\n",
    "            if not count == 0:\n",
    "                if 'type' in tmp:\n",
    "                    tmp = 'normal ' \n",
    "                print(tmp+':')\n",
    "                print(\"number of runs detected as anomaly: \" + str(anomaly_count) + \" from \" + str(count))\n",
    "                lst.append(anomaly_count/count)\n",
    "            count = 0\n",
    "            anomaly_count = 0\n",
    "            tmp = key.split('\\\\')[1] # tmp == <normal/anomaly>\\\\<scenario>\\\\<run>\n",
    "        count += 1\n",
    "        if dict_results[key] > 0:\n",
    "            anomaly_count += 1\n",
    "    if 'type' in tmp:\n",
    "        tmp = 'normal ' \n",
    "    print(tmp+':')\n",
    "    print(\"number of runs detected as anomaly: \" + str(anomaly_count) + \" from \" + str(count))\n",
    "    lst.append(anomaly_count / count)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, mic_or_mac):\n",
    "    trainings_preds, positives_preds, negatives_preds = data.get_predictions()\n",
    "    trainings_names, positives_names, negatives_names = data.get_names()\n",
    "    multi_paths_preds = [zip(positives_names, positives_preds), zip(negatives_names, negatives_preds)]\n",
    "    max_longest = find_max_longest_sequence(trainings_names, trainings_preds)\n",
    "    dict_preds = dict_sum_preds(multi_paths_preds, max_longest, {})\n",
    "    print(\"summarize Result for \" + \" features:\")\n",
    "    return dict_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9a767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_results(mic_dict_preds, mac_dict_preds):\n",
    "    union_dict_preds = {}\n",
    "    for key in mic_dict_preds.keys():\n",
    "        union_dict_preds[key] = mic_dict_preds[key] + mac_dict_preds[key]\n",
    "    return sum_result(union_dict_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f18d0e",
   "metadata": {},
   "source": [
    "# Run\n",
    "The data is stored in CSV files. Each experiment has normal and abnormal data. Multiple runs residing in the same folder correspond to the same behavior (either normal or the same anomaly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c9c4b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      " ------------------real_panda------------------ \n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      " ------------ Prediction based on spesific topic's values ------------ \n",
      " \n",
      "----------------------- EPS =     0.4904604636324936    min group =    28  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 10\n",
      "change_obj_weight:\n",
      "number of runs detected as anomaly: 18 from 18\n",
      "gripper_attack:\n",
      "number of runs detected as anomaly: 15 from 15\n",
      "low_net_connection:\n",
      "number of runs detected as anomaly: 4 from 17\n",
      "miss_bubble:\n",
      "number of runs detected as anomaly: 12 from 12\n",
      "\n",
      " ------------ Prediction based on statistics on topics ------------ \n",
      " \n",
      "----------------------- EPS =     1.0438122635752896    min group =    28  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 10\n",
      "change_obj_weight:\n",
      "number of runs detected as anomaly: 0 from 18\n",
      "gripper_attack:\n",
      "number of runs detected as anomaly: 0 from 15\n",
      "low_net_connection:\n",
      "number of runs detected as anomaly: 17 from 17\n",
      "miss_bubble:\n",
      "number of runs detected as anomaly: 0 from 12\n",
      "\n",
      " ---------------------- Union Results --------------------- \n",
      "\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 10\n",
      "change_obj_weight:\n",
      "number of runs detected as anomaly: 18 from 18\n",
      "gripper_attack:\n",
      "number of runs detected as anomaly: 15 from 15\n",
      "low_net_connection:\n",
      "number of runs detected as anomaly: 17 from 17\n",
      "miss_bubble:\n",
      "number of runs detected as anomaly: 12 from 12\n",
      "\n",
      "-------------------------------------------------\n",
      " ------------------sim_panda------------------ \n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      " ------------ Prediction based on spesific topic's values ------------ \n",
      " \n",
      "----------------------- EPS =     0.6068880967099358    min group =    28  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 6\n",
      "collision:\n",
      "number of runs detected as anomaly: 3 from 3\n",
      "drop_early:\n",
      "number of runs detected as anomaly: 6 from 7\n",
      "gripper_attack:\n",
      "number of runs detected as anomaly: 10 from 15\n",
      "\n",
      " ------------ Prediction based on statistics on topics ------------ \n",
      " \n",
      "----------------------- EPS =     1.1305839121419328    min group =    28  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 6\n",
      "collision:\n",
      "number of runs detected as anomaly: 0 from 3\n",
      "drop_early:\n",
      "number of runs detected as anomaly: 0 from 7\n",
      "gripper_attack:\n",
      "number of runs detected as anomaly: 5 from 15\n",
      "\n",
      " ---------------------- Union Results --------------------- \n",
      "\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 6\n",
      "collision:\n",
      "number of runs detected as anomaly: 3 from 3\n",
      "drop_early:\n",
      "number of runs detected as anomaly: 6 from 7\n",
      "gripper_attack:\n",
      "number of runs detected as anomaly: 12 from 15\n",
      "\n",
      "-------------------------------------------------\n",
      " ------------------real_turtlebot3------------------ \n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      " ------------ Prediction based on spesific topic's values ------------ \n",
      " \n",
      "----------------------- EPS =     0.04967965287449602    min group =    4  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 9\n",
      "collision:\n",
      "number of runs detected as anomaly: 0 from 15\n",
      "hardware_fault:\n",
      "number of runs detected as anomaly: 0 from 12\n",
      "low_net_connection:\n",
      "number of runs detected as anomaly: 1 from 16\n",
      "unmapped_obstacle:\n",
      "number of runs detected as anomaly: 1 from 15\n",
      "velocity_attack:\n",
      "number of runs detected as anomaly: 0 from 15\n",
      "\n",
      " ------------ Prediction based on statistics on topics ------------ \n",
      " \n",
      "----------------------- EPS =     0.2379525430218138    min group =    28  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 9\n",
      "collision:\n",
      "number of runs detected as anomaly: 9 from 15\n",
      "hardware_fault:\n",
      "number of runs detected as anomaly: 8 from 12\n",
      "low_net_connection:\n",
      "number of runs detected as anomaly: 16 from 16\n",
      "unmapped_obstacle:\n",
      "number of runs detected as anomaly: 1 from 15\n",
      "velocity_attack:\n",
      "number of runs detected as anomaly: 12 from 15\n",
      "\n",
      " ---------------------- Union Results --------------------- \n",
      "\n",
      "normal :\n",
      "number of runs detected as anomaly: 0 from 9\n",
      "collision:\n",
      "number of runs detected as anomaly: 9 from 15\n",
      "hardware_fault:\n",
      "number of runs detected as anomaly: 8 from 12\n",
      "low_net_connection:\n",
      "number of runs detected as anomaly: 16 from 16\n",
      "unmapped_obstacle:\n",
      "number of runs detected as anomaly: 2 from 15\n",
      "velocity_attack:\n",
      "number of runs detected as anomaly: 12 from 15\n",
      "\n",
      "-------------------------------------------------\n",
      " ------------------sim_turtlebot3------------------ \n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      " ------------ Prediction based on spesific topic's values ------------ \n",
      " \n",
      "----------------------- EPS =     0.05132169717414992    min group =    4  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 1 from 9\n",
      "laser_fault:\n",
      "number of runs detected as anomaly: 6 from 15\n",
      "unmapped_obstacle:\n",
      "number of runs detected as anomaly: 4 from 15\n",
      "velocity_attack:\n",
      "number of runs detected as anomaly: 6 from 15\n",
      "\n",
      " ------------ Prediction based on statistics on topics ------------ \n",
      " \n",
      "----------------------- EPS =     0.46049624940361095    min group =    28  -----------------------\n",
      "summarize Result for  features:\n",
      "normal :\n",
      "number of runs detected as anomaly: 2 from 9\n",
      "laser_fault:\n",
      "number of runs detected as anomaly: 1 from 15\n",
      "unmapped_obstacle:\n",
      "number of runs detected as anomaly: 1 from 15\n",
      "velocity_attack:\n",
      "number of runs detected as anomaly: 3 from 15\n",
      "\n",
      " ---------------------- Union Results --------------------- \n",
      "\n",
      "normal :\n",
      "number of runs detected as anomaly: 3 from 9\n",
      "laser_fault:\n",
      "number of runs detected as anomaly: 7 from 15\n",
      "unmapped_obstacle:\n",
      "number of runs detected as anomaly: 4 from 15\n",
      "velocity_attack:\n",
      "number of runs detected as anomaly: 8 from 15\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENTS = [\"real_panda\", \"sim_panda\", \"real_turtlebot3\", \"sim_turtlebot3\"]\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    df = pd.DataFrame()\n",
    "    print(\"\\n-------------------------------------------------\\n ------------------\" + exp + \"------------------ \\n-------------------------------------------------\\n\")\n",
    "\n",
    "    exp_ds = DS.Datasets(\"data/\"+exp+\"/normal/\", \"data/\"+exp+\"/abnormal/\", test_size=0.3)\n",
    "    similar_columns = exp_ds.find_similar_columns_in_training()\n",
    "    exp_ds.filter_by_columns(similar_columns)\n",
    "    exp_ds.normalization()\n",
    "    \n",
    "    # creating 'micro' datasets\n",
    "    mic_or_mac = \"micro\"\n",
    "    mic_datasets = exp_ds.get_copied_datasets()\n",
    "    mic_datasets = filter_topics(mic_datasets, get_mic_topics(exp))\n",
    "    \n",
    "    # predict\n",
    "    print(\"\\n ------------ Prediction based on spesific topic's values ------------ \\n \")\n",
    "    mic_datasets, mic_predictions = run_dbscan(mic_datasets)\n",
    "    exp_ds.set_predictions(mic_predictions[0], mic_predictions[1], mic_predictions[2])\n",
    "    mic_dict_preds = predict(exp_ds, mic_or_mac)\n",
    "    df[exp+\"_\"+mic_or_mac] = sum_result(mic_dict_preds)\n",
    "\n",
    "    # creating 'macro' datasests\n",
    "    mic_or_mac = \"macro\"\n",
    "    mac_datasets = exp_ds.get_copied_datasets()\n",
    "    mac_datasets = DS.drop_topics(mac_datasets, get_mic_topics(exp)) # drop topics values from database, only statistic topics left\n",
    "    mac_datasets = filter_topics(mac_datasets, most_influence_feature_by_pca(mac_datasets, n=27))\n",
    "    \n",
    "    # predict\n",
    "    print(\"\\n ------------ Prediction based on statistics on topics ------------ \\n \")\n",
    "    mac_datasets, mac_predictions = run_dbscan(mac_datasets)\n",
    "    exp_ds.set_predictions(mac_predictions[0], mac_predictions[1], mac_predictions[2])\n",
    "    mac_dict_preds = predict(exp_ds, mic_or_mac)\n",
    "    df[exp+\"_\"+mic_or_mac] = sum_result(mac_dict_preds)\n",
    "    \n",
    "    #union predictions\n",
    "    print(\"\\n ---------------------- Union Results --------------------- \\n\")\n",
    "    df[exp+\"_union\"] = union_results(mic_dict_preds, mac_dict_preds)\n",
    "    df.to_excel('C:\\\\Users\\Avior\\PycharmProjects\\ROS-DBSCAN\\\\'+exp+'-result.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
